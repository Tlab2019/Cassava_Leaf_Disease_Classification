{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 3.572171,
     "end_time": "2021-02-18T12:20:30.656121",
     "exception": false,
     "start_time": "2021-02-18T12:20:27.083950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import torch.utils.data as data\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import timm\n",
    "import gc\n",
    "\n",
    "\n",
    "# from bi_tempered_loss_pytorch import bi_tempered_logistic_loss\n",
    "# from temperature_scaling import ModelWithTemperature\n",
    "\n",
    "#import lightgbm as lgb\n",
    "import pickle\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.026949,
     "end_time": "2021-02-18T12:20:30.695257",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.668308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'rootpath': osp.join('..',\"..\",'input','cassava-leaf-disease-classification'),\n",
    "    'seed': 334,\n",
    "    'num_folds': 5,\n",
    "    \n",
    "    # augmentaion params\n",
    "    'aug': {\n",
    "        'ver': 'V3',\n",
    "        'size': 512,\n",
    "#         'size': 384,\n",
    "#         'size': 224,\n",
    "        'mean': (0.485, 0.456, 0.406),\n",
    "        'std': (0.229, 0.224, 0.225),\n",
    "#         'degrees': 45,\n",
    "        'degrees': 90,\n",
    "        'brightness': 0.3,\n",
    "        'contrast': 0.3,\n",
    "    },\n",
    "    \n",
    "    'do_mix': False,\n",
    "    'do_TemperatureScaling': False,\n",
    "    'freezeBN': True,\n",
    "    \n",
    "    # loss params\n",
    "    'loss': {\n",
    "#         'name': 'CrossEntropyLoss',\n",
    "        'name': 'BiTemperedLogisticLoss',\n",
    "        't1': 0.2,\n",
    "        't2': 1.2,\n",
    "#         't2': 4.0,\n",
    "#         'label_smoothing': 0.01,\n",
    "        'label_smoothing': 0.05,\n",
    "        'num_iters': 5,\n",
    "        'reduction': 'mean'\n",
    "    },\n",
    "\n",
    "#     'model_name': 'resnet50',\n",
    "#     'model_name': 'resnext50_32x4d',\n",
    "#     'model_name': 'seresnext50_32x4d',\n",
    "    'model_name': 'tf_efficientnet_b4_ns',\n",
    "    'batch_size': 8,\n",
    "    'test_batch_size': 1,\n",
    "    'num_epochs': 10,\n",
    "    'set_all': True,\n",
    "    \n",
    "    # optim params\n",
    "    'optim': {\n",
    "#         'name': 'SGD',\n",
    "        'name': 'Adam',\n",
    "        'lr': 1e-04,\n",
    "        'T_0': 10,   # CosineAnnealingWarmRestarts\n",
    "        'T_mult': 1,   # CosineAnnealingWarmRestarts\n",
    "        'min_lr': 1e-06,   # CosineAnnealingWarmRestarts\n",
    "        'last_epoch': -1,   # CosineAnnealingWarmRestarts\n",
    "        'weight_decay': 1e-06\n",
    "    },\n",
    "    \n",
    "    'tta': {\n",
    "        #'num': 8\n",
    "        'num': 5,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.028871,
     "end_time": "2021-02-18T12:20:30.735193",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.706322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    def __init__(self, resize, mean, std, degrees=45, brightness=0.3, contrast=0.3):\n",
    "        self.data_transform = {\n",
    "            'V1': {\n",
    "                'train': transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ]),\n",
    "                'val': transforms.Compose([\n",
    "                    transforms.Resize(resize),\n",
    "                    transforms.CenterCrop(resize),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ]),\n",
    "                'test': transforms.Compose([\n",
    "                    transforms.Resize(resize),\n",
    "                    transforms.CenterCrop(resize),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ])                \n",
    "            },\n",
    "            'V2': {\n",
    "                'train': transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomVerticalFlip(),\n",
    "                    transforms.RandomRotation(degrees),\n",
    "                    transforms.ColorJitter(brightness, contrast),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ]),\n",
    "                'val': transforms.Compose([\n",
    "                    transforms.Resize(resize),\n",
    "                    transforms.CenterCrop(resize),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ]),\n",
    "                'test': transforms.Compose([\n",
    "                    transforms.Resize(resize),\n",
    "                    transforms.CenterCrop(resize),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ])\n",
    "            },\n",
    "            'V3': {\n",
    "                'train': transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(resize),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomVerticalFlip(),\n",
    "                    transforms.RandomRotation(degrees),\n",
    "                    transforms.ColorJitter(brightness, contrast),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ]),\n",
    "                'val': transforms.Compose([\n",
    "                    transforms.Resize(resize),\n",
    "                    transforms.CenterCrop(resize),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ]),\n",
    "                'test': transforms.Compose([\n",
    "                    transforms.Resize(resize),\n",
    "                    transforms.CenterCrop(resize),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean, std)\n",
    "                ])\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, ver='V1', phase='train'):\n",
    "        return self.data_transform[ver][phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.022468,
     "end_time": "2021-02-18T12:20:30.768921",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.746453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(data.Dataset):\n",
    "    def __init__(self, filepath2label, transform=None, ver='V1', phase='train', output_label=True):\n",
    "        self.file_list = list(filepath2label.keys())\n",
    "        self.transform = transform\n",
    "        self.filepath2label = filepath2label\n",
    "        self.ver = ver\n",
    "        self.phase = phase\n",
    "        self.output_label = output_label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img, self.ver, self.phase)\n",
    "        if self.output_label:\n",
    "            label = self.filepath2label[img_path]\n",
    "            return img, label\n",
    "        else:\n",
    "            return img        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.019057,
     "end_time": "2021-02-18T12:20:30.799505",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.780448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_DataLoader(dataset, batch_size, shuffle=True):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.019924,
     "end_time": "2021-02-18T12:20:30.830750",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.810826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.02049,
     "end_time": "2021-02-18T12:20:30.862590",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.842100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomEfficientNet(nn.Module):\n",
    "    def __init__(self, model_name='tf_efficientnet_b4_ns', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, 5)\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.024541,
     "end_time": "2021-02-18T12:20:30.898650",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.874109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_network(model_name, use_pretrained=True):\n",
    "    if model_name == 'vgg19':\n",
    "        net = models.vgg19(pretrained=use_pretrained)\n",
    "        net.classifier[6] = nn.Linear(in_features=4096, out_features=5, bias=True)\n",
    "        update_param_names = ['classifier.6.weight', 'classifier.6.bias']\n",
    "    elif model_name == 'resnet50':\n",
    "        net = models.resnet50(pretrained=use_pretrained)\n",
    "        net.fc = nn.Linear(in_features=2048, out_features=5, bias=True)\n",
    "        update_param_names = ['fc.weight', 'fc.bias']\n",
    "    elif model_name == 'resnext50_32x4d':\n",
    "        net = CustomResNext(model_name=model_name, pretrained=use_pretrained)\n",
    "        update_param_names = ['model.fc.weight', 'model.fc.bias']\n",
    "    elif model_name == 'seresnext50_32x4d':\n",
    "        net = CustomResNext(model_name=model_name, pretrained=use_pretrained)\n",
    "        update_param_names = ['model.fc.weight', 'model.fc.bias']\n",
    "    elif model_name == 'tf_efficientnet_b5_ns':\n",
    "        net = CustomEfficientNet(model_name=model_name, pretrained=use_pretrained)\n",
    "        update_param_names = ['model.classifier.weight', 'model.classifier.bias']\n",
    "    elif model_name == 'tf_efficientnet_b4_ns':\n",
    "        net = CustomEfficientNet(model_name=model_name, pretrained=use_pretrained)\n",
    "        update_param_names = ['model.classifier.weight', 'model.classifier.bias']\n",
    "    elif model_name == 'tf_efficientnet_b3_ns':\n",
    "        net = CustomEfficientNet(model_name=model_name, pretrained=use_pretrained)\n",
    "        update_param_names = ['model.classifier.weight', 'model.classifier.bias']\n",
    "    elif model_name == 'tf_efficientnet_b1_ns':\n",
    "        net = CustomEfficientNet(model_name=model_name, pretrained=use_pretrained)\n",
    "        update_param_names = ['model.classifier.weight', 'model.classifier.bias']\n",
    "        \n",
    "    return net, update_param_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.025614,
     "end_time": "2021-02-18T12:20:30.935879",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.910265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_test_data_tta(net, dataloader, device):\n",
    "    net.eval()\n",
    "    preds = []\n",
    "#     bar = tqdm(dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            if config['tta']['num'] == 8:\n",
    "                inputs = torch.stack([inputs, inputs.flip(-1), inputs.flip(-2), inputs.flip(-1,-2),\n",
    "                                      inputs.transpose(-1,-2), inputs.transpose(-1,-2).flip(-1), \n",
    "                                      inputs.transpose(-1,-2).flip(-2), inputs.transpose(-1,-2).flip(-1,-2)], 0)\n",
    "            elif config['tta']['num'] == 5:\n",
    "                inputs = torch.stack([inputs, inputs.flip(-1), inputs.flip(-2), inputs.flip(-1,-2),\n",
    "                                      inputs.transpose(-1,-2)], 0)\n",
    "            inputs = inputs.view(-1, 3, config['aug']['size'], config['aug']['size'])\n",
    "            logits = net(inputs)\n",
    "            logits = logits.view(config['test_batch_size'], config['tta']['num'], -1).mean(1)\n",
    "            preds += [torch.softmax(logits, 1).detach().cpu()]\n",
    "        preds = torch.cat(preds).cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.021375,
     "end_time": "2021-02-18T12:20:30.969212",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.947837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    # set random seed\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.020446,
     "end_time": "2021-02-18T12:20:31.001929",
     "exception": false,
     "start_time": "2021-02-18T12:20:30.981483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_datapath_list(rootpath, phase='train'):\n",
    "    target_path = osp.join(rootpath, phase+'_images', '*.jpg')\n",
    "\n",
    "    path_list = []\n",
    "    for path in glob.glob(target_path):\n",
    "        path_list.append(path)\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.023745,
     "end_time": "2021-02-18T12:20:31.037786",
     "exception": false,
     "start_time": "2021-02-18T12:20:31.014041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_filename_info(title, ext, model_name, fold, aug_ver, loss_name, num_epochs, batch_size, size, set_all, lr, do_mix, freezeBN):\n",
    "    if loss_name == 'CrossEntropyLoss':\n",
    "        filename = title+'_'+model_name+'_fold'+str(fold)+'_'+aug_ver+'_loss'+loss_name+'_epoch'+str(num_epochs)+'_batchsize'+str(batch_size)+'_imgsize'+str(size)+'_allparams'+str(set_all)+'_lr'+str(lr)+'_Mix'+str(do_mix)+'_freezeBN'+str(freezeBN)+ext\n",
    "    elif loss_name == 'BiTemperedLogisticLoss':\n",
    "        filename = title+'_'+model_name+'_fold'+str(fold)+'_'+aug_ver+'_loss'+loss_name+'_t1'+str(config['loss']['t1'])+'_t2'+str(config['loss']['t2'])+'_labelsmoothing'+str(config['loss']['label_smoothing'])+'_epoch'+str(num_epochs)+'_batchsize'+str(batch_size)+'_imgsize'+str(size)+'_allparams'+str(set_all)+'_lr'+str(lr)+'_Mix'+str(do_mix)+'_freezeBN'+str(freezeBN)+ext\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_list = np.sort(glob.glob(os.path.join('..\\\\..\\\\input\\\\stacking_ensemble_data\\\\resnet50',\"*.pth\")))\n",
    "efnetb1_list = np.sort(glob.glob(os.path.join('..\\\\..\\\\input\\\\stacking_ensemble_data\\\\tf_efficientnet_b1_ns',\"*.pth\")))\n",
    "efnetb4_list = np.sort(glob.glob(os.path.join('..\\\\..\\\\input\\\\stacking_ensemble_data\\\\tf_efficientnet_b4_ns',\"*.pth\")))\n",
    "efnetb5_list = np.sort(glob.glob(os.path.join('..\\\\..\\\\input\\\\stacking_ensemble_data\\\\tf_efficientnet_b5_ns',\"*.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 35.348953,
     "end_time": "2021-02-18T12:21:06.398873",
     "exception": false,
     "start_time": "2021-02-18T12:20:31.049920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use device:  cuda\n",
      "..\\..\\input\\stacking_ensemble_data\\resnet50\\model_resnet50_fold0.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\resnet50\\model_resnet50_fold1.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\resnet50\\model_resnet50_fold2.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\resnet50\\model_resnet50_fold3.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\resnet50\\model_resnet50_fold4.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b1_ns\\model_tf_efficientnet_b1_ns_fold0.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b1_ns\\model_tf_efficientnet_b1_ns_fold1.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b1_ns\\model_tf_efficientnet_b1_ns_fold2.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b1_ns\\model_tf_efficientnet_b1_ns_fold3.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b1_ns\\model_tf_efficientnet_b1_ns_fold4.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b4_ns\\model_tf_efficientnet_b4_ns_fold0.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b4_ns\\model_tf_efficientnet_b4_ns_fold1.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b4_ns\\model_tf_efficientnet_b4_ns_fold2.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b4_ns\\model_tf_efficientnet_b4_ns_fold3.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b4_ns\\model_tf_efficientnet_b4_ns_fold4.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b5_ns\\model_tf_efficientnet_b5_ns_fold0.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b5_ns\\model_tf_efficientnet_b5_ns_fold1.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b5_ns\\model_tf_efficientnet_b5_ns_fold2.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b5_ns\\model_tf_efficientnet_b5_ns_fold3.pth\n",
      "..\\..\\input\\stacking_ensemble_data\\tf_efficientnet_b5_ns\\model_tf_efficientnet_b5_ns_fold4.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_random_seed(config['seed'])\n",
    "\n",
    "# device setting\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"use device: \", device)\n",
    "\n",
    "#test_datalist = np.sort(make_datapath_list(config['rootpath'], 'test'))\n",
    "test_datalist = np.sort(make_datapath_list(config['rootpath'], 'train'))[:100]\n",
    "\n",
    "test_filepath2label = dict(zip(test_datalist, [0] * len(test_datalist)))\n",
    "test_dataset = CassavaDataset(test_filepath2label, ImageTransform(config['aug']['size'], config['aug']['mean'], config['aug']['std'], config['aug']['degrees'], config['aug']['brightness'], config['aug']['contrast']), config['aug']['ver'], 'test', False)\n",
    "test_dataloader = get_DataLoader(test_dataset, config['test_batch_size'], False)\n",
    "test_preds = []\n",
    "\n",
    "inputs_metamodel = np.array([])\n",
    "\n",
    "\n",
    "feature_col = []\n",
    "#########################################\n",
    "### TTA pred resnet50 ###\n",
    "#########################################\n",
    "test_preds = []\n",
    "model_list = resnet50_list\n",
    "feature_col += [\"resnet50-c%d_proba\"%i for i in range(5)]\n",
    "for load_path in model_list:\n",
    "    print(load_path)\n",
    "    load_weights = torch.load(load_path, map_location=device)\n",
    "    net, update_param_names = get_network('resnet50', False)\n",
    "    net.load_state_dict(load_weights)\n",
    "    net.to(device)\n",
    "    test_preds += [inference_test_data_tta(net, test_dataloader, device)]\n",
    "\n",
    "if inputs_metamodel.size == 0:\n",
    "    inputs_metamodel = np.mean(test_preds, axis=0)\n",
    "else:\n",
    "    inputs_metamodel = np.hstack([inputs_metamodel, np.mean(test_preds, axis=0)])\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "### TTA pred efficient net b1 ###\n",
    "#########################################\n",
    "test_preds = []\n",
    "feature_col += [\"tf_efficientnet_b1_ns-c%d_proba\"%i for i in range(5)]\n",
    "model_list = efnetb1_list\n",
    "for load_path in model_list:\n",
    "    print(load_path)\n",
    "    load_weights = torch.load(load_path, map_location=device)\n",
    "    net, update_param_names = get_network('tf_efficientnet_b1_ns', False)\n",
    "    net.load_state_dict(load_weights)\n",
    "    net.to(device)\n",
    "    test_preds += [inference_test_data_tta(net, test_dataloader, device)]\n",
    "\n",
    "if inputs_metamodel.size == 0:\n",
    "    inputs_metamodel = np.mean(test_preds, axis=0)\n",
    "else:\n",
    "    inputs_metamodel = np.hstack([inputs_metamodel, np.mean(test_preds, axis=0)])\n",
    "\n",
    "\n",
    "#########################################\n",
    "### TTA pred efficient net b4 ###\n",
    "#########################################\n",
    "test_preds = []\n",
    "feature_col += [\"tf_efficientnet_b4_ns-c%d_proba\"%i for i in range(5)]\n",
    "model_list = efnetb4_list\n",
    "for load_path in model_list:\n",
    "    print(load_path)\n",
    "    load_weights = torch.load(load_path, map_location=device)\n",
    "    net, update_param_names = get_network('tf_efficientnet_b4_ns', False)\n",
    "    net.load_state_dict(load_weights)\n",
    "    net.to(device)\n",
    "    test_preds += [inference_test_data_tta(net, test_dataloader, device)]\n",
    "\n",
    "if inputs_metamodel.size == 0:\n",
    "    inputs_metamodel = np.mean(test_preds, axis=0)\n",
    "else:\n",
    "    inputs_metamodel = np.hstack([inputs_metamodel, np.mean(test_preds, axis=0)])\n",
    "\n",
    "\n",
    "#########################################\n",
    "### TTA pred efficient net b4 ###\n",
    "#########################################\n",
    "test_preds = []\n",
    "feature_col += [\"tf_efficientnet_b5_ns-c%d_proba\"%i for i in range(5)]\n",
    "model_list = efnetb5_list\n",
    "for load_path in model_list:\n",
    "    print(load_path)\n",
    "    load_weights = torch.load(load_path, map_location=device)\n",
    "    net, update_param_names = get_network('tf_efficientnet_b5_ns', False)\n",
    "    net.load_state_dict(load_weights)\n",
    "    net.to(device)\n",
    "    test_preds += [inference_test_data_tta(net, test_dataloader, device)]\n",
    "\n",
    "if inputs_metamodel.size == 0:\n",
    "    inputs_metamodel = np.mean(test_preds, axis=0)\n",
    "else:\n",
    "    inputs_metamodel = np.hstack([inputs_metamodel, np.mean(test_preds, axis=0)])\n",
    "\n",
    "\n",
    "    \n",
    "del net, load_weights, test_preds, test_dataloader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame(index = [osp.basename(k) for k in test_datalist],\n",
    "                      columns = feature_col,\n",
    "                      data = inputs_metamodel)\n",
    "sub_df[\"label\"] = 0\n",
    "sub_df.index.name = \"image_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class StackingDataset(data.Dataset):\n",
    "    def __init__(self, df,features,target):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        label = self.df[self.target].values[index]\n",
    "        img = np.array(self.df[self.features].iloc[index])\n",
    "        img = img.reshape([-1,5])[np.newaxis,:,:]\n",
    "        img = torch.from_numpy(img)\n",
    "\n",
    "        return img.float(), int(label)\n",
    "\n",
    "test_dataloader = DataLoader(StackingDataset(sub_df,feature_col,\"label\"),\n",
    "                              batch_size=1,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my2DCNN(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(1, 3), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2048, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.8, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class my2DCNN(nn.Module):\n",
    "    def __init__(self,model_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(1,8,kernel_size=(1,3),stride=1,padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(8,16,kernel_size=(1,3),stride=1,padding=0),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*model_num*1,2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(2048,5)\n",
    "        )\n",
    "        \n",
    "        self.model_num = model_num\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.feature(x)\n",
    "        x = x.view(-1,16*self.model_num*1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def check_cnn_size(self,x):\n",
    "        out = self.feature(x)\n",
    "        return out\n",
    "\n",
    "meta_model_path = \"2D_CNN-Adam(lr0.0001)-BiTLLoss(0.2,1.2)-epoch56.pth\"\n",
    "meta_model = my2DCNN(model_num=4)\n",
    "meta_model.load_state_dict(torch.load(meta_model_path))\n",
    "print(meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 659.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1016334938.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1016415263.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10169000.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1016955090.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1017006970.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id  label\n",
       "0   1000015157.jpg      0\n",
       "1   1000201771.jpg      3\n",
       "2    100042118.jpg      4\n",
       "3   1000723321.jpg      1\n",
       "4   1000812911.jpg      3\n",
       "..             ...    ...\n",
       "95  1016334938.jpg      3\n",
       "96  1016415263.jpg      1\n",
       "97    10169000.jpg      1\n",
       "98  1016955090.jpg      2\n",
       "99  1017006970.jpg      3\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = [\"label\"]\n",
    "    \n",
    "meta_model.eval()\n",
    "meta_model = meta_model.to(device)\n",
    "outputs = []\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "\n",
    "    X = batch[0].to(device)\n",
    "    y = batch[1].to(device)\n",
    "\n",
    "    pred = meta_model(X)\n",
    "    pred = torch.nn.Softmax(dim=1)(pred)\n",
    "    pred = pred.cpu().detach().numpy()\n",
    "    pred = pred.argmax(axis=1)\n",
    "\n",
    "    pred = pd.DataFrame(columns=cols,\n",
    "                         data=pred)\n",
    "\n",
    "    outputs.append(pred)\n",
    "outputs = pd.concat(outputs)\n",
    "outputs = outputs.reset_index(drop=True)\n",
    "\n",
    "sub_df = sub_df.reset_index()\n",
    "sub_df = sub_df.drop(columns={\"label\"},axis=15)\n",
    "\n",
    "sub_df = pd.concat( [sub_df, outputs], axis=1 )\n",
    "sub_df = sub_df[[\"image_id\",\"label\"]]\n",
    "sub_df.to_csv(\"submission.csv\",index=False)\n",
    "\n",
    "display(sub_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.68551,
   "end_time": "2021-02-18T12:21:08.452342",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-18T12:20:21.766832",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
