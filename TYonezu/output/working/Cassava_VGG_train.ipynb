{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cassava VGG training**\n",
    "2021/12/09 written by T.Yonezu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cassava_dataset import *\n",
    "from myvgg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join('..',\"..\", 'input', 'cassava-leaf-disease-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\organ\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv(os.path.join(input_dir, 'train.csv'))\n",
    "x[\"image_path\"] = os.path.join(input_dir,\"train_images\")\n",
    "x[\"image_path\"] = x[\"image_path\"].str.cat(x[\"image_id\"], sep=os.path.sep)\n",
    "\n",
    "train_dict = dict( zip(x[\"image_path\"],x[\"label\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (224,224)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "transform = ImageTransform(size,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "train_data = CassavaDataset(train_dict,transform=transform)\n",
    "train_data = DataLoader(train_data,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_NUM = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 1/500 [03:32<29:24:13, 212.13s/it]"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "model = VGG11(num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# in your training loop:\n",
    "for epoch in tqdm(range(EPOCH_NUM)):\n",
    "    for batch in (train_data):\n",
    "        \n",
    "        X = batch[0].cuda()\n",
    "        y = batch[1].cuda()\n",
    "\n",
    "        pred = model(X)\n",
    "\n",
    "        # zero the gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
